{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "153a37a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edced689",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "df3bf90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    'IQ' : [80,60,70,120],\n",
    "    'CGPA' : [8,9,5,7],\n",
    "    'LPA' : [3,5,8,11]\n",
    "})\n",
    "X = data.drop('LPA',axis=1,inplace=False)\n",
    "y = data['LPA']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88121731",
   "metadata": {},
   "source": [
    "#### Initialization of trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dbb13a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1,w2,b = 0.0,0.0,1.0\n",
    "lr = 0.001\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dc2f95",
   "metadata": {},
   "source": [
    "#### Back Propagation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8a5ce767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Average training loss: 778363.3730858236 \n",
      "W1 = -407.84676827392; W2 = -23.735484365312; B = -2.316220015616\n",
      "\n",
      "Epoch: 2\n",
      "Average training loss: 270607453779783.03 \n",
      "W1 = -7606082.088312182; W2 = -442746.89523456316; B = -61851.90880785588\n",
      "\n",
      "Epoch: 3\n",
      "Average training loss: 9.410705308105273e+22 \n",
      "W1 = -141841142991.10068; W2 = -8256514510.305152; B = -1153456837.2996247\n",
      "\n",
      "Epoch: 4\n",
      "Average training loss: 3.272687966670876e+31 \n",
      "W1 = -2645108158991785.0; W2 = -153970656436780.2; B = -21510106515608.883\n",
      "\n",
      "Epoch: 5\n",
      "Average training loss: 1.1381173011523924e+40 \n",
      "W1 = -4.932699374259045e+19; W2 = -2.871303988376223e+18; B = -4.0112873490298675e+17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,epochs+1):\n",
    "    total_loss = 0.0\n",
    "    for i in range(len(X)):\n",
    "        # i = random.randint(0,len(X)-1)\n",
    "        x1, x2 = X.iloc[i]\n",
    "        yi = y[i]\n",
    "\n",
    "        # forward propagation\n",
    "        y_pred = w1*x1+w2*x2+b \n",
    "\n",
    "        # Calculate loss\n",
    "        loss = np.mean((y_pred-yi)**2)\n",
    "        total_loss += loss\n",
    "\n",
    "        # Gradient calculation\n",
    "        dl_dy = 2*(y_pred-yi) \n",
    "        dw1 = dl_dy*x1\n",
    "        dw2 = dl_dy*x2\n",
    "        db = dl_dy\n",
    "\n",
    "        # update parameters\n",
    "        w1 -= lr*dw1\n",
    "        w2 -= lr*dw2\n",
    "        b -= lr*db\n",
    "\n",
    "    avg_loss = total_loss/len(X)\n",
    "    print(f\"Epoch: {epoch}\\nAverage training loss: {avg_loss} \\nW1 = {w1}; W2 = {w2}; B = {b}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".Rup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
